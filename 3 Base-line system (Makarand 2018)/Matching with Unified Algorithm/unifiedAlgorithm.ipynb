{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# for MIR-QBSH query\n",
    "def read_semitone_from_MIR_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            truth.append(file.split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH manually labelled query\n",
    "def read_semitone_from_MIR_manual_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".pv\"):\n",
    "            list_query_name.append(file.replace(\".pv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            temp_df = temp_df.to_numpy().flatten()\n",
    "            round_df = []\n",
    "            for i in temp_df:\n",
    "                if i!=0:\n",
    "                    round_df.append(round(i))\n",
    "            df_query.append(round_df)\n",
    "            truth.append(file.replace(\".pv\",\"\").split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for IOACAS_QBH query\n",
    "def read_semitone_from_IOACAS_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    truth_file = os.path.join(dir_query, \"query_truth.list\")\n",
    "\n",
    "    # read csv as string type need converters\n",
    "    truth_df = pd.read_csv(truth_file, header=None, sep=\"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "    all_truth = truth_df[1].values.astype(str).flatten()\n",
    "    # print(\"all truth\", all_truth)\n",
    "    all_wav = []\n",
    "\n",
    "    for wav in truth_df[0]:\n",
    "        all_wav.append(wav.split(\"\\\\\")[1].replace(\".wav\",\"\"))\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            # index_truth = all_wav.index(\"002_010\")\n",
    "            index_truth = all_wav.index(file.split(\"-\")[0])\n",
    "            truth.append(str(all_truth[index_truth]))\n",
    "    # print(\"one truth\", truth)\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH and IOACAS-QBH database\n",
    "def read_note_from_midi(dir_midi):\n",
    "    pickled_semitone = \"pickled_\"+dir_midi.replace(folder_data+\"\\\\\",\"\")\n",
    "    dir_pickle = os.path.join(folder_pickle,pickled_semitone)\n",
    "\n",
    "    if os.path.exists(dir_pickle):\n",
    "        open_file = open(dir_pickle, \"rb\")\n",
    "        list_dir_midi, df_midi = pickle.load(open_file)\n",
    "        open_file.close()\n",
    "    else:\n",
    "        open_file = open(dir_pickle, \"wb\")\n",
    "        list_dir_midi = []\n",
    "        df_midi = []\n",
    "\n",
    "        for file in os.listdir(dir_midi):\n",
    "            if file.endswith(\".csv\"):\n",
    "                list_dir_midi.append(file.replace(\".mid.csv\",\"\"))\n",
    "                file_path = os.path.join(dir_midi, file)\n",
    "                fields = [\"note_index\"]\n",
    "                temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "                df_midi.append(temp_df.to_numpy().flatten())\n",
    "        pickle.dump([list_dir_midi, df_midi], open_file)\n",
    "        open_file.close()\n",
    "\n",
    "    return list_dir_midi, df_midi\n",
    "\n",
    "# calculate relative distance\n",
    "def calc_rel_dis(df):\n",
    "    res = []\n",
    "    length = len(df)\n",
    "    for i in range(length-1):\n",
    "        dis = float(df[i+1] - df[i])\n",
    "        res.append(dis)\n",
    "\n",
    "#     ada di eksperimen 1, tapi kayaknya nggak masuk akal kalau dipake\n",
    "#     res = remove_consecutive(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "# remove consecutive distance in list of relative distance \n",
    "def remove_consecutive(list, isQuery):\n",
    "    if isQuery == True:\n",
    "        # eksperimen 1, 3\n",
    "        # list = remove_only_consecutive(list)\n",
    "\n",
    "        # eksperimen 2, 5, 6\n",
    "        list = get_only_10_consecutive_notes(list)\n",
    "            \n",
    "        # eksperimen 4\n",
    "        # list = get_exact_10_consecutive_notes(list)\n",
    "        \n",
    "    else:\n",
    "        # eksperimen 2 dan 4\n",
    "        # do nothing\n",
    "        \n",
    "        # eksperimen 1, 3, 5\n",
    "        list = remove_only_consecutive(list)\n",
    "\n",
    "    return list\n",
    "\n",
    "def remove_only_consecutive(list):\n",
    "    i = 0\n",
    "    while i < len(list)-1:\n",
    "        if list[i] == list[i+1]:\n",
    "            del list[i]\n",
    "        else:\n",
    "            i = i+1\n",
    "    return list\n",
    "\n",
    "from itertools import groupby\n",
    "def get_only_10_consecutive_notes(ls):\n",
    "    res = []\n",
    "    n = 10\n",
    "    for k, v in groupby(ls):\n",
    "        value = list(v)\n",
    "        if len(value) >= n:\n",
    "            res.append(value[0])\n",
    "    return res\n",
    "\n",
    "def get_exact_10_consecutive_notes(list):\n",
    "    res = []\n",
    "    i = 0\n",
    "    while i < len(list)-9:\n",
    "        cur = list[i]\n",
    "        marker = True\n",
    "        for j in range(1,10):\n",
    "            if cur != list[i+j]:\n",
    "                marker = False\n",
    "                i+=j-1\n",
    "                break\n",
    "        if marker == True:\n",
    "            res.append(cur)\n",
    "            i+=10\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "    return res\n",
    "\n",
    "# arrange index according to its similarity, more similar is less in index\n",
    "def get_all_rank_max(ls):\n",
    "    res = []\n",
    "    for i in ls:\n",
    "        temp = ls.index(max(ls))\n",
    "        res.append(list_dir_midi[temp])\n",
    "        ls[temp] = 0\n",
    "    return res\n",
    "\n",
    "# arrange index according to its distance, less distance is less in index\n",
    "def get_all_rank_min(ls):\n",
    "    res = []\n",
    "    for i in ls:\n",
    "        temp = ls.index(min(ls))\n",
    "        res.append(list_dir_midi[temp])\n",
    "        ls[temp] = sys.maxsize\n",
    "    return res\n",
    "\n",
    "# get rank from ground truth\n",
    "def get_rank(rank, truth):\n",
    "    try:\n",
    "        return rank.index(truth)+1\n",
    "    except ValueError as error:\n",
    "        return sys.maxsize\n",
    "    \n",
    "# get top ten rank\n",
    "def get_top_ten(rank):\n",
    "    return rank[:10]\n",
    "\n",
    "# get inverted index from all midi\n",
    "def get_inverted_index_midi(dis_midi, list_dir_midi):\n",
    "    # create inverted index for 2-grams, 3-grams, 4-grams in all midi\n",
    "    import hashedindex\n",
    "    RP4G = hashedindex.HashedIndex()\n",
    "    RP3G = hashedindex.HashedIndex()\n",
    "    RP2G = hashedindex.HashedIndex()\n",
    "\n",
    "    # example:\n",
    "    # midi relative distance : +1 +1 +4\n",
    "    # 2-grams are +1 and +4\n",
    "    # 3-grams are +1 +1 and +1 +3\n",
    "    # 4-grams is +1 +1 +4\n",
    "\n",
    "    # print(dis_midi[0])\n",
    "\n",
    "    # inserting 2-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for note in dis_midi[midiNumber]:\n",
    "            RP2G.add_term_occurrence(note, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 2-grams\n",
    "    # RP2G.get_documents((2.0))\n",
    "\n",
    "    # inserting 3-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-1):\n",
    "            term = (dis_midi[midiNumber][noteNumber], dis_midi[midiNumber][noteNumber+1])\n",
    "            RP3G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 3-grams\n",
    "    # RP3G.get_documents((2.0, 0.0))\n",
    "\n",
    "    # inserting 4-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-2):\n",
    "            term = (dis_midi[midiNumber][noteNumber], \n",
    "            dis_midi[midiNumber][noteNumber+1], dis_midi[midiNumber][noteNumber+2])\n",
    "            \n",
    "            RP4G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 4-grams\n",
    "    # RP4G.get_documents((2.0, 0.0, -2.0))\n",
    "\n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "# get lists containing 4-grams, 3-grams, and 2-grams from each query\n",
    "def get_ngrams_query(dis_query):\n",
    "    RP4G = []\n",
    "    RP3G = []\n",
    "    RP2G = []\n",
    "\n",
    "    # inserting list of 4-grams\n",
    "    for noteNumber in range(len(dis_query)-2):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1], dis_query[noteNumber+2])\n",
    "        RP4G.append(term)\n",
    "\n",
    "    # inserting list of 3-grams\n",
    "    for noteNumber in range(len(dis_query)-1):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1])\n",
    "        RP3G.append(term)\n",
    "\n",
    "    # inserting list of 2-grams\n",
    "    RP2G = dis_query\n",
    "    \n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "from collections import Counter\n",
    "# get Counter containing number of query appearances in inverted index\n",
    "def get_counter_grams(index, query):\n",
    "    res = Counter()\n",
    "    for grams in query:\n",
    "        try:\n",
    "            res += index.get_documents(grams)\n",
    "        except IndexError as error:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "# get rank from counter grams\n",
    "def get_rank_from_counter_grams(res_grams, truth):\n",
    "    rank = []\n",
    "    for i in res_grams.most_common():\n",
    "        rank.append(i[0])\n",
    "    return rank\n",
    "\n",
    "def get_rank_truth_from_counter_grams(rank, truth):\n",
    "    try:\n",
    "        rankTruth = get_rank(rank, truth)\n",
    "    except ValueError as error:\n",
    "        rankTruth = sys.maxsize\n",
    "    return rankTruth\n",
    "\n",
    "# get rank with relative pitch 4-grams (RP4G), 3-grams (RP3G) and 2-grams (RP2G)\n",
    "def get_rank_with_rpg(dis_query, truth, index_midi):\n",
    "    index4G, index3G, index2G = index_midi\n",
    "    query4G, query3G, query2G = get_ngrams_query(dis_query)\n",
    "\n",
    "    # 4-grams\n",
    "    res_4grams = get_counter_grams(index4G, query4G)\n",
    "\n",
    "    # 3-grams\n",
    "    res_3grams = get_counter_grams(index3G, query3G)\n",
    "\n",
    "    # 2-grams\n",
    "    res_2grams = get_counter_grams(index2G, query2G)\n",
    "\n",
    "    res_rank = []\n",
    "    res_rankTruth = []\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_4grams, truth)\n",
    "    topTen = get_top_ten(rank)\n",
    "    res_rank.append(topTen)\n",
    "    res_rankTruth.append(get_rank_truth_from_counter_grams(rank, truth))\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_3grams, truth)\n",
    "    topTen = get_top_ten(rank)\n",
    "    res_rank.append(topTen)\n",
    "    res_rankTruth.append(get_rank_truth_from_counter_grams(rank, truth))\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_2grams, truth)\n",
    "    topTen = get_top_ten(rank)\n",
    "    res_rank.append(topTen)\n",
    "    res_rankTruth.append(get_rank_truth_from_counter_grams(rank, truth))\n",
    "\n",
    "    return res_rankTruth, res_rank\n",
    "\n",
    "def subsequent_MNF(ref, hyp):    \n",
    "    res = 0\n",
    "    if len(hyp)>len(ref):\n",
    "        hyp, ref = ref, hyp\n",
    "    \n",
    "    diff = len(ref) - len(hyp)\n",
    "    for i in range(diff+1):\n",
    "        subRef = ref[i:i+len(hyp)]\n",
    "        ratio = edit_distance.SequenceMatcher(a=subRef, b=hyp).ratio()\n",
    "        if (res<ratio):\n",
    "            res = ratio\n",
    "\n",
    "    return res\n",
    "\n",
    "# get rank with Mode Normalised Frequency using edit distance method\n",
    "def get_rank_with_mnf(df_query, truth, midi_MNF):\n",
    "    # ref = dis_midi\n",
    "    # hyp = dis_query\n",
    "\n",
    "    hyp = convert_df_to_MNF(df_query)\n",
    "\n",
    "    hyp = remove_consecutive(hyp, isQuery = True)\n",
    "    \n",
    "    list_ratio = []\n",
    "    for ref in midi_MNF:\n",
    "        sm = edit_distance.SequenceMatcher(a=ref, b=hyp)\n",
    "        list_ratio.append(sm.ratio())\n",
    "#         ratio = subsequent_MNF(ref, hyp)\n",
    "#         list_ratio.append(ratio)\n",
    "    \n",
    "    rank = get_all_rank_max(list_ratio)\n",
    "    rankTruth = get_rank(rank, truth)\n",
    "\n",
    "    # show top ten result\n",
    "    topTen = get_top_ten(rank)\n",
    "    # print(topTen)\n",
    "\n",
    "    return rankTruth, topTen\n",
    "\n",
    "# get best rank from both nGrams and edit distance method\n",
    "def get_rank_with_unified_algorithm(dis_query, df_query, truth, index_midi, midi_MNF):\n",
    "    rank = []\n",
    "    topTen = []\n",
    "\n",
    "    temp_rank, temp_topTen = get_rank_with_rpg(dis_query, truth, index_midi)\n",
    "    for r in temp_rank:\n",
    "        rank.append(r)\n",
    "    for t in temp_topTen:\n",
    "        topTen.append(t)\n",
    "\n",
    "    try:\n",
    "        temp_rank, temp_topTen = get_rank_with_mnf(df_query, truth, midi_MNF)\n",
    "        rank.append(temp_rank)\n",
    "        topTen.append(temp_topTen)\n",
    "    except ValueError as error:\n",
    "        pass\n",
    "    except IndexError as error:\n",
    "        pass\n",
    "\n",
    "    bestIndex = rank.index(min(rank))\n",
    "    bestRank = rank[bestIndex]\n",
    "    bestTopTen = topTen[bestIndex]\n",
    "\n",
    "    # to return which algorithm: RP4G, RP3G, RP2G, or MNF\n",
    "    switcher = {\n",
    "        0: \"RP4G\",\n",
    "        1: \"RP3G\",\n",
    "        2: \"RP2G\",\n",
    "        3: \"MNF\"\n",
    "    }\n",
    "    alg = switcher.get(bestIndex)\n",
    "\n",
    "    return bestRank, bestTopTen, alg\n",
    "\n",
    "# convert one dataframe containing semitone to Mode Normalised Frequency (MNF)\n",
    "def convert_df_to_MNF(df):\n",
    "    from collections import Counter\n",
    "    res = []\n",
    "    data = Counter(df)\n",
    "\n",
    "    data = data.most_common()\n",
    "    mode = data[0][0]\n",
    "    adder = int(78-mode) # mode marked as char 'N' which is 78 in ascii\n",
    "\n",
    "    for i in df:\n",
    "        res.append(chr(int(i+adder)))\n",
    "        # res.append(i)\n",
    "\n",
    "    # print(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "# count MRR from a list of rank from some queries\n",
    "def count_MRR(list_rank):\n",
    "    mrr = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            mrr+=1/rank\n",
    "            counter+=1\n",
    "    return round(mrr/counter,2), counter\n",
    "\n",
    "# count top 1 hit ratios from list rank\n",
    "def count_top_1_ratio(list_rank):\n",
    "    count_top1 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank == 1:\n",
    "                count_top1+=1\n",
    "            counter+=1\n",
    "    return round(count_top1/counter,2), counter\n",
    "\n",
    "# count top 3 hit ratios from list rank\n",
    "def count_top_3_ratio(list_rank):\n",
    "    count_top3 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 3:\n",
    "                count_top3+=1\n",
    "            counter+=1\n",
    "    return round(count_top3/counter,2), counter\n",
    "\n",
    "# count top 5 hit ratios from list rank\n",
    "def count_top_5_ratio(list_rank):\n",
    "    count_top5 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 5:\n",
    "                count_top5+=1\n",
    "            counter+=1\n",
    "    return round(count_top5/counter,2), counter\n",
    "\n",
    "# count top 10 hit ratios from list rank\n",
    "def count_top_10_ratio(list_rank):\n",
    "    count_top10 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 10:\n",
    "                count_top10+=1\n",
    "            counter+=1\n",
    "    return round(count_top10/counter,2), counter\n",
    "\n",
    "def print_result_to_file(process_name):\n",
    "    from datetime import datetime\n",
    "\n",
    "    dateTimeObj = str(datetime.now())+\".txt\"\n",
    "    dateTimeObj = dateTimeObj.replace(\":\",\"-\")\n",
    "    filename = os.path.join(folder_hasil, process_name + ' ' + dateTimeObj)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(cap.stdout)\n",
    "\n",
    "from tslearn.metrics import dtw_subsequence_path as dtw\n",
    "def get_rank_with_dtw(df_query, df_midi, truth):\n",
    "    res = sys.maxsize\n",
    "    list_dist = []\n",
    "    \n",
    "    query = get_only_10_consecutive_notes(df_query)\n",
    "\n",
    "    if len(query)==0:\n",
    "        return sys.maxsize\n",
    "\n",
    "    for midi in df_midi:\n",
    "        path, dist = dtw(query, midi)\n",
    "        list_dist.append(dist)\n",
    "\n",
    "    rank = get_all_rank_min(list_dist)\n",
    "\n",
    "    rankTruth = get_rank(rank, truth)\n",
    "\n",
    "    return rankTruth\n",
    "\n",
    "def process_query():\n",
    "    # calculate relative distance in all query and midi\n",
    "    dis_query, dis_midi = get_rel_dis_query_midi(df_query, df_midi)\n",
    "\n",
    "    index_midi = get_inverted_index_midi(dis_midi, list_dir_midi)\n",
    "\n",
    "    midi_MNF = []\n",
    "    for i in df_midi:\n",
    "        temp = convert_df_to_MNF(i)\n",
    "        temp = remove_consecutive(temp, isQuery = False)\n",
    "        midi_MNF.append(temp)\n",
    "\n",
    "    list_rank = []\n",
    "    list_time = []\n",
    "\n",
    "    process_name = dir_query.replace(folder_data+\"\\\\\",\"\")+\" with \"+dir_midi.replace(folder_data+\"\\\\\",\"\")\n",
    "    print(\"Start process\", process_name)\n",
    "\n",
    "    for i in range(len(df_query)):\n",
    "        print(\"Processing...\",i+1,\"/\",len(df_query))\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # eksperimen 1,2,3,4,5\n",
    "        rankTruth, topTen, alg = get_rank_with_unified_algorithm(dis_query[i], df_query[i], truth[i], index_midi, midi_MNF)\n",
    "\n",
    "        # eksperimen 6\n",
    "        # rankTruth = get_rank_with_dtw(df_query[i], df_midi, truth[i])\n",
    "        \n",
    "        list_time.append(round(time.time() - start_time, 3))\n",
    "\n",
    "        list_rank.append(rankTruth)\n",
    "\n",
    "        # show ground truth from a query\n",
    "        # print(\"query\",list_query_name[i],\"truth is\",truth[i])\n",
    "\n",
    "        print(\"query\",list_query_name[i],\"truth is on rank\",rankTruth)\n",
    "        # print(\"top ten result from\",alg,\":\",topTen)\n",
    "\n",
    "    print(\"Finish process\", process_name)\n",
    "    \n",
    "    try:\n",
    "        mrr, counter = count_MRR(list_rank)\n",
    "        print(\"MRR:\", mrr, \"from\", counter, \"queries\")\n",
    "\n",
    "        hit_ratio, counter = count_top_1_ratio(list_rank)\n",
    "        print(\"Top 1 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_3_ratio(list_rank)\n",
    "        print(\"Top 3 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_5_ratio(list_rank)\n",
    "        print(\"Top 5 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_10_ratio(list_rank)\n",
    "        print(\"Top 10 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "        \n",
    "        print(\"Avg time:\", round(sum(list_time)/len(list_time), 3))\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        print(\"No result to show\")\n",
    "        print(\"list rank\", list_rank)\n",
    "        print(\"list time\", list_time)\n",
    "\n",
    "    return process_name\n",
    "\n",
    "# convert pitch to semitone\n",
    "def convert_f0_to_semitone(f0):\n",
    "    import math\n",
    "\n",
    "    res = []\n",
    "    for freq in f0:\n",
    "        res.append(round(12*math.log((freq/440),2)+69))\n",
    "    return res\n",
    "\n",
    "# extract pitch and semitone with parselmouth from wav to csv\n",
    "def extract_pitch_with_parselmouth_to_csv(folder, dir_out):\n",
    "    import parselmouth\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(dir_wav_query, file)\n",
    "\n",
    "            snd = parselmouth.Sound(file_path)\n",
    "\n",
    "            pitch = snd.to_pitch()\n",
    "            pitch_values = pitch.selected_array['frequency']\n",
    "\n",
    "            time = []\n",
    "            f0 = []\n",
    "\n",
    "            for i in range(len(pitch_values)):\n",
    "                if pitch_values[i]!=0:\n",
    "                    f0.append(pitch_values[i].round(decimals=3))\n",
    "                    time.append(pitch.xs()[i].round(decimals=3))\n",
    "\n",
    "            file = file_path.split(\"\\\\\")\n",
    "            file_csv = os.path.join(dir_out, file[2] + \"-parselmouth.csv\")\n",
    "            file_csv = file_csv.replace(\".wav\",\"\")\n",
    "\n",
    "            semitone = convert_f0_to_semitone(f0)\n",
    "\n",
    "            pd.DataFrame({'time':time, 'semitone':semitone, 'f0':f0}).to_csv(file_csv, index=False)\n",
    "\n",
    "# extract pitch and semitone with DNN-LSTM from wav to csv\n",
    "def extract_pitch_with_DNN_LSTM_to_csv(folder, dir_out):\n",
    "    import shutil\n",
    "    \n",
    "    folder_project_DNN_LSTM = \"Lab_MelExt\"\n",
    "\n",
    "    dir_temp_in = os.path.join(folder_project_DNN_LSTM, \"temp_query\")\n",
    "    if not os.path.exists(dir_temp_in):\n",
    "        os.mkdir(dir_temp_in)\n",
    "\n",
    "    for i in os.listdir(folder):\n",
    "        source = os.path.join(folder, i)\n",
    "        destination = os.path.join(dir_temp_in, i)\n",
    "        shutil.copy(source, destination)\n",
    "\n",
    "    print(\"Start melody extraction with DNN-LSTM\")\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(folder_project_DNN_LSTM)\n",
    "    cmd_line = \"python predict.py temp_query temp_pitch\"\n",
    "    os.system(cmd_line)\n",
    "    os.chdir(cwd)\n",
    "    print(\"Finish melody extraction with DNN-LSTM\")\n",
    "\n",
    "    dir_temp_query = os.path.join(folder_project_DNN_LSTM, \"temp_pitch\")\n",
    "\n",
    "    for file in os.listdir(dir_temp_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            filePath = os.path.join(dir_temp_query, file)\n",
    "            df = pd.read_csv(filePath, sep=\"\\t\", header=None)\n",
    "\n",
    "            time = []\n",
    "            f0 = []\n",
    "\n",
    "            for i in range(len(df[1])):\n",
    "                if df[1][i]!=0:\n",
    "                    time.append(df[0][i].round(decimals=3))\n",
    "                    f0.append(df[1][i].round(decimals=3))\n",
    "                    \n",
    "            semitone = convert_f0_to_semitone(f0)\n",
    "\n",
    "            file_csv = os.path.join(dir_out, file)\n",
    "\n",
    "            pd.DataFrame({'time':time, 'semitone':semitone, 'f0':f0}).to_csv(file_csv, index=False)\n",
    "    \n",
    "    shutil.rmtree(dir_temp_in)\n",
    "    shutil.rmtree(dir_temp_query)\n",
    "\n",
    "def extract_pitch_to_csv(extractor, folder, dir_out):\n",
    "    if extractor == \"parselmouth\":\n",
    "        extract_pitch_with_parselmouth_to_csv(folder, dir_out)\n",
    "    elif extractor == \"DNN-LSTM\":\n",
    "        extract_pitch_with_DNN_LSTM_to_csv(folder, dir_out)\n",
    "\n",
    "# choose midi based on dir_query\n",
    "def get_midi_dir(dir_query):\n",
    "    if \"48\" in dir_query:\n",
    "        dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH 48 MIDI\")\n",
    "    elif \"IOACAS\" in dir_query:\n",
    "        dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH\")\n",
    "    else:\n",
    "        dir_midi = os.path.join(folder_data, \"Database midi MIR-QBSH\")\n",
    "    \n",
    "    return dir_midi\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "def get_semitone_list(dir_query):\n",
    "    pickled_semitone = \"pickled_\"+dir_query.replace(folder_data+\"\\\\\",\"\")\n",
    "    dir_pickle = os.path.join(folder_pickle,pickled_semitone)\n",
    "\n",
    "    if os.path.exists(dir_pickle):\n",
    "        open_file = open(dir_pickle, \"rb\")\n",
    "        list_query_name, df_query, truth = pickle.load(open_file)\n",
    "        open_file.close()\n",
    "    else:\n",
    "        open_file = open(dir_pickle, \"wb\")\n",
    "        if \"manual\" in dir_query:\n",
    "            list_query_name, df_query, truth = read_semitone_from_MIR_manual_query(dir_query)\n",
    "        elif \"IOACAS\" in dir_query:\n",
    "            list_query_name, df_query, truth = read_semitone_from_IOACAS_query(dir_query)\n",
    "        else:\n",
    "            list_query_name, df_query, truth = read_semitone_from_MIR_query(dir_query)\n",
    "        pickle.dump([list_query_name, df_query, truth], open_file)\n",
    "        open_file.close()\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# calculate relative distance in all query and midi\n",
    "def get_rel_dis_query_midi(df_query, df_midi):\n",
    "    # calculate relative distance in all query\n",
    "    dis_query = []\n",
    "    for query in df_query:\n",
    "        dis_query.append(calc_rel_dis(query))\n",
    "\n",
    "    # calculate relative distance in all midi\n",
    "    dis_midi = []\n",
    "    for midi in df_midi:\n",
    "        dis_midi.append(calc_rel_dis(midi))\n",
    "\n",
    "    return dis_query, dis_midi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start process Test query MIR-QBSH_midi-to-wav_parselmouth with Database midi MIR-QBSH\n",
      "Processing... 1 / 48\n",
      "query year0000-person00000-00001-parselmouth truth is on rank 1\n",
      "Processing... 2 / 48\n",
      "query year0000-person00000-00002-parselmouth truth is on rank 1\n",
      "Processing... 3 / 48\n",
      "query year0000-person00000-00003-parselmouth truth is on rank 1\n",
      "Processing... 4 / 48\n",
      "query year0000-person00000-00004-parselmouth truth is on rank 1\n",
      "Processing... 5 / 48\n",
      "query year0000-person00000-00005-parselmouth truth is on rank 1\n",
      "Processing... 6 / 48\n",
      "query year0000-person00000-00006-parselmouth truth is on rank 1\n",
      "Processing... 7 / 48\n",
      "query year0000-person00000-00007-parselmouth truth is on rank 1\n",
      "Processing... 8 / 48\n",
      "query year0000-person00000-00008-parselmouth truth is on rank 1\n",
      "Processing... 9 / 48\n",
      "query year0000-person00000-00009-parselmouth truth is on rank 1\n",
      "Processing... 10 / 48\n",
      "query year0000-person00000-00010-parselmouth truth is on rank 1\n",
      "Processing... 11 / 48\n",
      "query year0000-person00000-00011-parselmouth truth is on rank 1\n",
      "Processing... 12 / 48\n",
      "query year0000-person00000-00012-parselmouth truth is on rank 1\n",
      "Processing... 13 / 48\n",
      "query year0000-person00000-00013-parselmouth truth is on rank 1\n",
      "Processing... 14 / 48\n",
      "query year0000-person00000-00014-parselmouth truth is on rank 1\n",
      "Processing... 15 / 48\n",
      "query year0000-person00000-00015-parselmouth truth is on rank 1\n",
      "Processing... 16 / 48\n",
      "query year0000-person00000-00016-parselmouth truth is on rank 1\n",
      "Processing... 17 / 48\n",
      "query year0000-person00000-00017-parselmouth truth is on rank 1\n",
      "Processing... 18 / 48\n",
      "query year0000-person00000-00018-parselmouth truth is on rank 1\n",
      "Processing... 19 / 48\n",
      "query year0000-person00000-00019-parselmouth truth is on rank 1\n",
      "Processing... 20 / 48\n",
      "query year0000-person00000-00020-parselmouth truth is on rank 1\n",
      "Processing... 21 / 48\n",
      "query year0000-person00000-00021-parselmouth truth is on rank 1\n",
      "Processing... 22 / 48\n",
      "query year0000-person00000-00022-parselmouth truth is on rank 1\n",
      "Processing... 23 / 48\n",
      "query year0000-person00000-00023-parselmouth truth is on rank 1\n",
      "Processing... 24 / 48\n",
      "query year0000-person00000-00024-parselmouth truth is on rank 1\n",
      "Processing... 25 / 48\n",
      "query year0000-person00000-00025-parselmouth truth is on rank 1\n",
      "Processing... 26 / 48\n",
      "query year0000-person00000-00026-parselmouth truth is on rank 1\n",
      "Processing... 27 / 48\n",
      "query year0000-person00000-00027-parselmouth truth is on rank 1\n",
      "Processing... 28 / 48\n",
      "query year0000-person00000-00028-parselmouth truth is on rank 4\n",
      "Processing... 29 / 48\n",
      "query year0000-person00000-00029-parselmouth truth is on rank 1\n",
      "Processing... 30 / 48\n",
      "query year0000-person00000-00030-parselmouth truth is on rank 1\n",
      "Processing... 31 / 48\n",
      "query year0000-person00000-00031-parselmouth truth is on rank 1\n",
      "Processing... 32 / 48\n",
      "query year0000-person00000-00032-parselmouth truth is on rank 1\n",
      "Processing... 33 / 48\n",
      "query year0000-person00000-00033-parselmouth truth is on rank 1\n",
      "Processing... 34 / 48\n",
      "query year0000-person00000-00034-parselmouth truth is on rank 1\n",
      "Processing... 35 / 48\n",
      "query year0000-person00000-00035-parselmouth truth is on rank 1\n",
      "Processing... 36 / 48\n",
      "query year0000-person00000-00036-parselmouth truth is on rank 1\n",
      "Processing... 37 / 48\n",
      "query year0000-person00000-00037-parselmouth truth is on rank 1\n",
      "Processing... 38 / 48\n",
      "query year0000-person00000-00038-parselmouth truth is on rank 4\n",
      "Processing... 39 / 48\n",
      "query year0000-person00000-00039-parselmouth truth is on rank 1\n",
      "Processing... 40 / 48\n",
      "query year0000-person00000-00040-parselmouth truth is on rank 1\n",
      "Processing... 41 / 48\n",
      "query year0000-person00000-00041-parselmouth truth is on rank 1\n",
      "Processing... 42 / 48\n",
      "query year0000-person00000-00042-parselmouth truth is on rank 1\n",
      "Processing... 43 / 48\n",
      "query year0000-person00000-00043-parselmouth truth is on rank 1\n",
      "Processing... 44 / 48\n",
      "query year0000-person00000-00044-parselmouth truth is on rank 1\n",
      "Processing... 45 / 48\n",
      "query year0000-person00000-00045-parselmouth truth is on rank 1\n",
      "Processing... 46 / 48\n",
      "query year0000-person00000-00046-parselmouth truth is on rank 1\n",
      "Processing... 47 / 48\n",
      "query year0000-person00000-00047-parselmouth truth is on rank 1\n",
      "Processing... 48 / 48\n",
      "query year0000-person00000-00048-parselmouth truth is on rank 1\n",
      "Finish process Test query MIR-QBSH_midi-to-wav_parselmouth with Database midi MIR-QBSH\n",
      "MRR: 0.97 from 48 queries\n",
      "Top 1 ratio: 0.96 from 48 queries\n",
      "Top 3 ratio: 0.96 from 48 queries\n",
      "Top 5 ratio: 1.0 from 48 queries\n",
      "Top 10 ratio: 1.0 from 48 queries\n",
      "Avg time: 1.127\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "# read midi and query data\n",
    "# insert it into dataframe\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import edit_distance\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "folder_data = \"Data query dan midi\"\n",
    "folder_hasil = \"Hasil eksperimen\"\n",
    "folder_pickle = \"pickle\"\n",
    "\n",
    "if not os.path.exists(folder_hasil):\n",
    "    os.mkdir(folder_hasil)\n",
    "\n",
    "if not os.path.exists(folder_pickle):\n",
    "    os.mkdir(folder_pickle)\n",
    "\n",
    "# test query\n",
    "dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_midi-to-wav_parselmouth\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_midi-to-wav_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_parselmouth\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_manual label\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_parselmouth\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_parselmouth_48_MIDI\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_DNN-LSTM_48_MIDI\")\n",
    "\n",
    "# all query\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_parselmouth\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_manual label\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_parselmouth\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_parselmouth_48_MIDI\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM_48_MIDI\")\n",
    "\n",
    "# choose midi based on dir_query\n",
    "dir_midi = get_midi_dir(dir_query)\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "list_query_name, df_query, truth = get_semitone_list(dir_query)\n",
    "\n",
    "# read and insert note_index or semitone from midi to list of dataframe\n",
    "list_dir_midi, df_midi = read_note_from_midi(dir_midi)\n",
    "\n",
    "# test match with query data\n",
    "process_name = process_query()\n",
    "\n",
    "# place on different cell\n",
    "# print_result_to_file(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start melody extraction with DNN-LSTM\n",
      "Finish melody extraction with DNN-LSTM\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "# FOR DEMO PURPOSES\n",
    "# COMBINED ALL PROCESS FROM PITCH EXTRACTION TO MATCHING\n",
    "# PARSELMOUTH AND DNN-LSTM PITCH EXTRACTION\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import edit_distance\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "folder_data = \"Data query dan midi\"\n",
    "folder_hasil = \"Hasil eksperimen\"\n",
    "folder_pickle = \"pickle\"\n",
    "# folder_wav = \"Test wav query MIR-QBSH\"\n",
    "# folder_wav = \"Test wav query IOACAS_QBH\"\n",
    "# folder_wav = \"Test wav query IOACAS_QBH_48_MIDI\"\n",
    "folder_wav = \"Test wav query MIR-QBSH_midi-to-wav\"\n",
    "\n",
    "if not os.path.exists(folder_hasil):\n",
    "    os.mkdir(folder_hasil)\n",
    "\n",
    "# start pitch extraction\n",
    "\n",
    "# extractor = \"parselmouth\"\n",
    "extractor = \"DNN-LSTM\"\n",
    "\n",
    "dir_wav_query = os.path.join(folder_data, folder_wav)\n",
    "\n",
    "dir_query = dir_wav_query+\"_\"+extractor\n",
    "\n",
    "if not os.path.exists(dir_query):\n",
    "    os.mkdir(dir_query)\n",
    "\n",
    "# copy IOACAS ground truth list file\n",
    "if \"IOACAS\" in dir_wav_query:\n",
    "    source = os.path.join(dir_wav_query, \"query_truth.list\")\n",
    "    destination = os.path.join(dir_query, \"query_truth.list\")\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "extract_pitch_to_csv(extractor, dir_wav_query, dir_query)\n",
    "    \n",
    "# end pitch extraction\n",
    "\n",
    "# start matching\n",
    "\n",
    "# choose midi based on dir_query\n",
    "dir_midi = get_midi_dir(dir_query)\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "list_query_name, df_query, truth = get_semitone_list(dir_query)\n",
    "\n",
    "# read and insert note_index or semitone from midi to list of dataframe\n",
    "list_dir_midi, df_midi = read_note_from_midi(dir_midi)\n",
    "\n",
    "# test match with query data\n",
    "process_name = process_query()\n",
    "\n",
    "# place on different cell\n",
    "# print_result_to_file(process_name)\n",
    "\n",
    "# end matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}