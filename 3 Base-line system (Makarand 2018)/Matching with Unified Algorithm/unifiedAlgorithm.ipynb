{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# for MIR-QBSH query\n",
    "def read_semitone_from_MIR_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            truth.append(file.split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH manually labelled query\n",
    "def read_semitone_from_MIR_manual_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".pv\"):\n",
    "            list_query_name.append(file.replace(\".pv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            temp_df = temp_df.to_numpy().flatten()\n",
    "            round_df = []\n",
    "            for i in temp_df:\n",
    "                if i!=0:\n",
    "                    round_df.append(round(i))\n",
    "            df_query.append(round_df)\n",
    "            truth.append(file.replace(\".pv\",\"\").split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for IOACAS_QBH query\n",
    "def read_semitone_from_IOACAS_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    truth_file = os.path.join(dir_query, \"query_truth.list\")\n",
    "\n",
    "    # read csv as string type need converters\n",
    "    truth_df = pd.read_csv(truth_file, header=None, sep=\"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "    all_truth = truth_df[1].values.astype(str).flatten()\n",
    "    # print(\"all truth\", all_truth)\n",
    "    all_wav = []\n",
    "\n",
    "    for wav in truth_df[0]:\n",
    "        all_wav.append(wav.split(\"\\\\\")[1].replace(\".wav\",\"\"))\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            # index_truth = all_wav.index(\"002_010\")\n",
    "            index_truth = all_wav.index(file.split(\"-\")[0])\n",
    "            truth.append(str(all_truth[index_truth]))\n",
    "    # print(\"one truth\", truth)\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH and IOACAS-QBH database\n",
    "def read_note_from_midi(dir_midi):\n",
    "    list_dir_midi = []\n",
    "    df_midi = []\n",
    "\n",
    "    for file in os.listdir(dir_midi):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_dir_midi.append(file.replace(\".mid.csv\",\"\"))\n",
    "            file_path = os.path.join(dir_midi, file)\n",
    "            fields = [\"note_index\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_midi.append(temp_df.to_numpy().flatten())\n",
    "\n",
    "    return list_dir_midi, df_midi\n",
    "\n",
    "# calculate relative distance\n",
    "def calc_rel_dis(df):\n",
    "    res = []\n",
    "    length = len(df)\n",
    "    for i in range(length-1):\n",
    "        dis = float(df[i+1] - df[i])\n",
    "        res.append(dis)\n",
    "    res = remove_consecutive(res)\n",
    "    return res\n",
    "\n",
    "# remove consecutive distance in list of relative distance \n",
    "def remove_consecutive(list):\n",
    "    i = 0\n",
    "    while i < len(list)-1:\n",
    "        if list[i] == list[i+1]:\n",
    "            del list[i]\n",
    "        else:\n",
    "            i = i+1\n",
    "    return list\n",
    "\n",
    "# arrange index according to its similarity, more similar less \n",
    "def get_all_rank(ls):\n",
    "    res = []\n",
    "    for i in ls:\n",
    "        temp = ls.index(max(ls))\n",
    "        res.append(list_dir_midi[temp])\n",
    "        ls[temp] = 0\n",
    "    return res\n",
    "\n",
    "# get rank from ground truth\n",
    "def get_rank(rank, truth):\n",
    "    return rank.index(truth)+1\n",
    "\n",
    "# get top ten rank\n",
    "def get_top_ten(rank):\n",
    "    return rank[:10]\n",
    "\n",
    "# get inverted index from all midi\n",
    "def get_inverted_index_midi(dis_midi, list_dir_midi):\n",
    "    # create inverted index for 2-grams, 3-grams, 4-grams in all midi\n",
    "    import hashedindex\n",
    "    RP4G = hashedindex.HashedIndex()\n",
    "    RP3G = hashedindex.HashedIndex()\n",
    "    RP2G = hashedindex.HashedIndex()\n",
    "\n",
    "    # example:\n",
    "    # midi relative distance : +1 +1 +4\n",
    "    # 2-grams are +1 and +4\n",
    "    # 3-grams are +1 +1 and +1 +3\n",
    "    # 4-grams is +1 +1 +4\n",
    "\n",
    "    # print(dis_midi[0])\n",
    "\n",
    "    # inserting 2-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for note in dis_midi[midiNumber]:\n",
    "            RP2G.add_term_occurrence(note, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 2-grams\n",
    "    # RP2G.get_documents((2.0))\n",
    "\n",
    "    # inserting 3-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-1):\n",
    "            term = (dis_midi[midiNumber][noteNumber], dis_midi[midiNumber][noteNumber+1])\n",
    "            RP3G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 3-grams\n",
    "    # RP3G.get_documents((2.0, 0.0))\n",
    "\n",
    "    # inserting 4-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-2):\n",
    "            term = (dis_midi[midiNumber][noteNumber], \n",
    "            dis_midi[midiNumber][noteNumber+1], dis_midi[midiNumber][noteNumber+2])\n",
    "            \n",
    "            RP4G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 4-grams\n",
    "    # RP4G.get_documents((2.0, 0.0, -2.0))\n",
    "\n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "# get lists containing 4-grams, 3-grams, and 2-grams from each query\n",
    "def get_ngrams_query(dis_query):\n",
    "    RP4G = []\n",
    "    RP3G = []\n",
    "    RP2G = []\n",
    "\n",
    "    # inserting list of 4-grams\n",
    "    for noteNumber in range(len(dis_query)-2):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1], dis_query[noteNumber+2])\n",
    "        RP4G.append(term)\n",
    "\n",
    "    # inserting list of 3-grams\n",
    "    for noteNumber in range(len(dis_query)-1):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1])\n",
    "        RP3G.append(term)\n",
    "\n",
    "    # inserting list of 2-grams\n",
    "    RP2G = dis_query\n",
    "    \n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# get Counter containing number of query appearances in inverted index\n",
    "def get_counter_grams(index, query):\n",
    "    res = Counter()\n",
    "    for grams in query:\n",
    "        try:\n",
    "            res += index.get_documents(grams)\n",
    "        except IndexError as error:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "# get rank from \n",
    "def get_rank_from_counter_grams(res_grams, truth):\n",
    "    res = []\n",
    "    for i in res_grams.most_common():\n",
    "        res.append(i[0])\n",
    "    try:\n",
    "        rank = get_rank(res, truth)\n",
    "    except ValueError as error:\n",
    "        rank = sys.maxsize\n",
    "    return rank\n",
    "\n",
    "# get rank with relative pitch 4-grams (RP4G), 3-grams (RP3G) and 2-grams (RP2G)\n",
    "def get_rank_with_rpg(dis_query, truth):\n",
    "    index4G, index3G, index2G = get_inverted_index_midi(dis_midi, list_dir_midi)\n",
    "    query4G, query3G, query2G = get_ngrams_query(dis_query)\n",
    "\n",
    "    # 4-grams\n",
    "    res_4grams = get_counter_grams(index4G, query4G)\n",
    "\n",
    "    # 3-grams\n",
    "    res_3grams = get_counter_grams(index3G, query3G)\n",
    "\n",
    "    # 2-grams\n",
    "    res_2grams = get_counter_grams(index2G, query2G)\n",
    "\n",
    "    res_rank = []\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_4grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_3grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_2grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    return res_rank\n",
    "\n",
    "# get rank with Mode Normalised Frequency using edit distance method\n",
    "def get_rank_with_mnf(df_query, truth):\n",
    "    # ref = dis_midi\n",
    "    # hyp = dis_query\n",
    "\n",
    "    hyp = convert_df_to_MNF(df_query)\n",
    "    midi = []\n",
    "    for i in df_midi:\n",
    "        midi.append(convert_df_to_MNF(i))\n",
    "    \n",
    "    list_ratio = []\n",
    "    for ref in midi:\n",
    "        sm = edit_distance.SequenceMatcher(a=ref, b=hyp)\n",
    "        list_ratio.append(sm.ratio())\n",
    "    \n",
    "    rank = get_all_rank(list_ratio)\n",
    "    rankTruth = get_rank(rank, truth)\n",
    "\n",
    "    # show all rank\n",
    "    # print(\"All rank from MNF:\", rank)\n",
    "\n",
    "    # show top ten result\n",
    "    # print(\"Top ten from MNF:\", get_top_ten(rank))\n",
    "\n",
    "#     try:\n",
    "#         rankTruth = get_rank(rank, truth)\n",
    "#     except ValueError as error:\n",
    "#         rankTruth = len(dis_midi)\n",
    "    # topTen = get_top_ten(rank)\n",
    "\n",
    "    return rankTruth\n",
    "\n",
    "# get best rank from both nGrams and edit distance method\n",
    "def get_rank_with_unified_algorithm(dis_query, df_query, truth):\n",
    "    res = get_rank_with_rpg(dis_query, truth)\n",
    "\n",
    "    # comment lines below if not using MNF for faster retrieval\n",
    "    try:\n",
    "        res.append(get_rank_with_mnf(df_query, truth))\n",
    "    except ValueError as error:\n",
    "        pass\n",
    "    except IndexError as error:\n",
    "        pass\n",
    "\n",
    "    bestRank = min(res)\n",
    "    return bestRank\n",
    "\n",
    "# convert one dataframe containing semitone to Mode Normalised Frequency (MNF)\n",
    "def convert_df_to_MNF(df):\n",
    "    from collections import Counter\n",
    "    res = []\n",
    "    data = Counter(df)\n",
    "\n",
    "    data = data.most_common()\n",
    "    mode = data[0][0]\n",
    "    adder = int(78-mode) # mode marked as char 'N' which is 78 in ascii\n",
    "\n",
    "    for i in df:\n",
    "        res.append(chr(int(i+adder)))\n",
    "    res = remove_consecutive(res)\n",
    "    return res\n",
    "\n",
    "# count MRR from a list of rank from some queries\n",
    "def count_MRR(list_rank):\n",
    "    mrr = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            mrr+=1/rank\n",
    "            counter+=1\n",
    "    return round(mrr/counter,2), counter\n",
    "\n",
    "# count top 3 hit ratios from list rank\n",
    "def count_top_3_ratio(list_rank):\n",
    "    count_top3 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 3:\n",
    "                count_top3+=1\n",
    "            counter+=1\n",
    "    return round(count_top3/counter,2), counter\n",
    "\n",
    "# count top 5 hit ratios from list rank\n",
    "def count_top_5_ratio(list_rank):\n",
    "    count_top5 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 5:\n",
    "                count_top5+=1\n",
    "            counter+=1\n",
    "    return round(count_top5/counter,2), counter\n",
    "\n",
    "# count top 10 hit ratios from list rank\n",
    "def count_top_10_ratio(list_rank):\n",
    "    count_top10 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 10:\n",
    "                count_top10+=1\n",
    "            counter+=1\n",
    "    return round(count_top10/counter,2), counter\n",
    "\n",
    "def print_result_to_file(process_name):\n",
    "    from datetime import datetime\n",
    "\n",
    "    dateTimeObj = str(datetime.now())+\".txt\"\n",
    "    dateTimeObj = dateTimeObj.replace(\":\",\"-\")\n",
    "    filename = os.path.join(folder_hasil, process_name + ' ' + dateTimeObj)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(cap.stdout)\n",
    "\n",
    "def process_query():\n",
    "    process_name = dir_query.replace(folder_data+\"\\\\\",\"\")+\" with \"+dir_midi.replace(folder_data+\"\\\\\",\"\")\n",
    "    print(\"Start process\", process_name)\n",
    "\n",
    "    for i in range(len(dis_query)):\n",
    "        print(\"Processing...\",i+1,\"/\",len(dis_query))\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        rankTruth = get_rank_with_unified_algorithm(dis_query[i], df_query[i], truth[i])\n",
    "        \n",
    "        list_time.append(round(time.time() - start_time, 3))\n",
    "\n",
    "        list_rank.append(rankTruth)\n",
    "\n",
    "        # show ground truth from a query\n",
    "        # print(\"query\",list_query_name[i],\"truth is\",truth[i])\n",
    "\n",
    "        print(\"query\",list_query_name[i],\"truth is on rank\",rankTruth)\n",
    "\n",
    "    print(\"Finish process\", process_name)\n",
    "    \n",
    "    try:\n",
    "        mrr, counter = count_MRR(list_rank)\n",
    "        print(\"MRR:\", mrr, \"from\", counter, \"queries\")\n",
    "\n",
    "        hit_ratio, counter = count_top_3_ratio(list_rank)\n",
    "        print(\"Top 3 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_5_ratio(list_rank)\n",
    "        print(\"Top 5 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_10_ratio(list_rank)\n",
    "        print(\"Top 10 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "        \n",
    "        print(\"Avg time:\", round(sum(list_time)/len(list_time), 3))\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        print(\"No result to show\")\n",
    "        print(\"list rank\", list_rank)\n",
    "        print(\"list time\", list_time)\n",
    "\n",
    "    return process_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start process Test query MIR-QBSH with Database midi MIR-QBSH\n",
      "Processing... 1 / 5\n",
      "query year2003-person00001-00013-parselmouth truth is on rank 17\n",
      "Processing... 2 / 5\n",
      "query year2003-person00001-00014-parselmouth truth is on rank 2\n",
      "Processing... 3 / 5\n",
      "query year2003-person00001-00016-parselmouth truth is on rank 7\n",
      "Processing... 4 / 5\n",
      "query year2003-person00001-00017-parselmouth truth is on rank 8\n",
      "Processing... 5 / 5\n",
      "query year2003-person00001-00018-parselmouth truth is on rank 11\n",
      "Finish process Test query MIR-QBSH with Database midi MIR-QBSH\n",
      "MRR: 0.18 from 5 queries\n",
      "Top 3 ratio: 0.2 from 5 queries\n",
      "Top 5 ratio: 0.2 from 5 queries\n",
      "Top 10 ratio: 0.6 from 5 queries\n",
      "Avg time: 1.066\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "# read midi and query data\n",
    "# insert it into dataframe\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import edit_distance\n",
    "import time\n",
    "import sys\n",
    "\n",
    "folder_data = \"Data query dan midi\"\n",
    "folder_hasil = \"Hasil eksperimen\"\n",
    "\n",
    "if not os.path.exists(folder_hasil):\n",
    "    os.mkdir(folder_hasil)\n",
    "\n",
    "# test query\n",
    "dir_query = os.path.join(folder_data, \"Test query MIR-QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_manual label\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_DNN-LSTM\")\n",
    "\n",
    "# all query\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_manual label\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_48_MIDI\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM_48_MIDI\")\n",
    "\n",
    "# all midi\n",
    "dir_midi = os.path.join(folder_data, \"Database midi MIR-QBSH\")\n",
    "# dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH\")\n",
    "# dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH 48 MIDI\")\n",
    "\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "if \"manual\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_manual_query(dir_query)\n",
    "elif \"IOACAS\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_IOACAS_query(dir_query)\n",
    "else:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_query(dir_query)\n",
    "\n",
    "# read and insert note_index or semitone from midi to list of dataframe\n",
    "list_dir_midi, df_midi = read_note_from_midi(dir_midi)\n",
    "\n",
    "# calculate relative distance in all query\n",
    "dis_query = []\n",
    "for query in df_query:\n",
    "    dis_query.append(calc_rel_dis(query))\n",
    "\n",
    "# calculate relative distance in all midi\n",
    "dis_midi = []\n",
    "for midi in df_midi:\n",
    "    dis_midi.append(calc_rel_dis(midi))\n",
    "\n",
    "# ref = dis_midi\n",
    "# hyp = dis_query\n",
    "\n",
    "list_rank = []\n",
    "list_time = []\n",
    "\n",
    "# test match with query data\n",
    "process_name = process_query()\n",
    "\n",
    "# place on different cell\n",
    "# print_result_to_file(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}