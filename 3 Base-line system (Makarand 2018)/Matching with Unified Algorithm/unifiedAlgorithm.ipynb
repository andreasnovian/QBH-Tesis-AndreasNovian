{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# for MIR-QBSH query\n",
    "def read_semitone_from_MIR_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            truth.append(file.split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH manually labelled query\n",
    "def read_semitone_from_MIR_manual_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".pv\"):\n",
    "            list_query_name.append(file.replace(\".pv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            temp_df = temp_df.to_numpy().flatten()\n",
    "            round_df = []\n",
    "            for i in temp_df:\n",
    "                if i!=0:\n",
    "                    round_df.append(round(i))\n",
    "            df_query.append(round_df)\n",
    "            truth.append(file.replace(\".pv\",\"\").split(\"-\")[2])\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for IOACAS_QBH query\n",
    "def read_semitone_from_IOACAS_query(dir_query):\n",
    "    list_query_name = []\n",
    "    df_query = []\n",
    "    truth = []\n",
    "\n",
    "    truth_file = os.path.join(dir_query, \"query_truth.list\")\n",
    "\n",
    "    # read csv as string type need converters\n",
    "    truth_df = pd.read_csv(truth_file, header=None, sep=\"\\t\", converters={i: str for i in range(100)})\n",
    "\n",
    "    all_truth = truth_df[1].values.astype(str).flatten()\n",
    "    # print(\"all truth\", all_truth)\n",
    "    all_wav = []\n",
    "\n",
    "    for wav in truth_df[0]:\n",
    "        all_wav.append(wav.split(\"\\\\\")[1].replace(\".wav\",\"\"))\n",
    "\n",
    "    for file in os.listdir(dir_query):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_query_name.append(file.replace(\".csv\",\"\"))\n",
    "            file_path = os.path.join(dir_query, file)\n",
    "            fields = [\"semitone\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_query.append(temp_df.to_numpy().flatten())\n",
    "            # index_truth = all_wav.index(\"002_010\")\n",
    "            index_truth = all_wav.index(file.split(\"-\")[0])\n",
    "            truth.append(str(all_truth[index_truth]))\n",
    "    # print(\"one truth\", truth)\n",
    "\n",
    "    return list_query_name, df_query, truth\n",
    "\n",
    "# for MIR-QBSH and IOACAS-QBH database\n",
    "def read_note_from_midi(dir_midi):\n",
    "    list_dir_midi = []\n",
    "    df_midi = []\n",
    "\n",
    "    for file in os.listdir(dir_midi):\n",
    "        if file.endswith(\".csv\"):\n",
    "            list_dir_midi.append(file.replace(\".mid.csv\",\"\"))\n",
    "            file_path = os.path.join(dir_midi, file)\n",
    "            fields = [\"note_index\"]\n",
    "            temp_df = pd.read_csv(file_path, usecols=fields)\n",
    "            df_midi.append(temp_df.to_numpy().flatten())\n",
    "\n",
    "    return list_dir_midi, df_midi\n",
    "\n",
    "# calculate relative distance\n",
    "def calc_rel_dis(df):\n",
    "    res = []\n",
    "    length = len(df)\n",
    "    for i in range(length-1):\n",
    "        dis = float(df[i+1] - df[i])\n",
    "        res.append(dis)\n",
    "    res = remove_consecutive(res)\n",
    "    return res\n",
    "\n",
    "# remove consecutive distance in list of relative distance \n",
    "def remove_consecutive(list):\n",
    "    i = 0\n",
    "    while i < len(list)-1:\n",
    "        if list[i] == list[i+1]:\n",
    "            del list[i]\n",
    "        else:\n",
    "            i = i+1\n",
    "    return list\n",
    "\n",
    "# arrange index according to its similarity, more similar less \n",
    "def get_all_rank(ls):\n",
    "    res = []\n",
    "    for i in ls:\n",
    "        temp = ls.index(max(ls))\n",
    "        res.append(list_dir_midi[temp])\n",
    "        ls[temp] = 0\n",
    "    return res\n",
    "\n",
    "# get rank from ground truth\n",
    "def get_rank(rank, truth):\n",
    "    return rank.index(truth)+1\n",
    "\n",
    "# get top ten rank\n",
    "def get_top_ten(rank):\n",
    "    return rank[:10]\n",
    "\n",
    "# get inverted index from all midi\n",
    "def get_inverted_index_midi(dis_midi, list_dir_midi):\n",
    "    # create inverted index for 2-grams, 3-grams, 4-grams in all midi\n",
    "    import hashedindex\n",
    "    RP4G = hashedindex.HashedIndex()\n",
    "    RP3G = hashedindex.HashedIndex()\n",
    "    RP2G = hashedindex.HashedIndex()\n",
    "\n",
    "    # example:\n",
    "    # midi relative distance : +1 +1 +4\n",
    "    # 2-grams are +1 and +4\n",
    "    # 3-grams are +1 +1 and +1 +3\n",
    "    # 4-grams is +1 +1 +4\n",
    "\n",
    "    # print(dis_midi[0])\n",
    "\n",
    "    # inserting 2-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for note in dis_midi[midiNumber]:\n",
    "            RP2G.add_term_occurrence(note, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 2-grams\n",
    "    # RP2G.get_documents((2.0))\n",
    "\n",
    "    # inserting 3-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-1):\n",
    "            term = (dis_midi[midiNumber][noteNumber], dis_midi[midiNumber][noteNumber+1])\n",
    "            RP3G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 3-grams\n",
    "    # RP3G.get_documents((2.0, 0.0))\n",
    "\n",
    "    # inserting 4-grams as inverted index\n",
    "    for midiNumber in range(len(dis_midi)):\n",
    "        for noteNumber in range(len(dis_midi[midiNumber])-2):\n",
    "            term = (dis_midi[midiNumber][noteNumber], \n",
    "            dis_midi[midiNumber][noteNumber+1], dis_midi[midiNumber][noteNumber+2])\n",
    "            \n",
    "            RP4G.add_term_occurrence(term, list_dir_midi[midiNumber])\n",
    "\n",
    "    # test 4-grams\n",
    "    # RP4G.get_documents((2.0, 0.0, -2.0))\n",
    "\n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "# get lists containing 4-grams, 3-grams, and 2-grams from each query\n",
    "def get_ngrams_query(dis_query):\n",
    "    RP4G = []\n",
    "    RP3G = []\n",
    "    RP2G = []\n",
    "\n",
    "    # inserting list of 4-grams\n",
    "    for noteNumber in range(len(dis_query)-2):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1], dis_query[noteNumber+2])\n",
    "        RP4G.append(term)\n",
    "\n",
    "    # inserting list of 3-grams\n",
    "    for noteNumber in range(len(dis_query)-1):\n",
    "        term = (dis_query[noteNumber], dis_query[noteNumber+1])\n",
    "        RP3G.append(term)\n",
    "\n",
    "    # inserting list of 2-grams\n",
    "    RP2G = dis_query\n",
    "    \n",
    "    return RP4G, RP3G, RP2G\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# get Counter containing number of query appearances in inverted index\n",
    "def get_counter_grams(index, query):\n",
    "    res = Counter()\n",
    "    for grams in query:\n",
    "        try:\n",
    "            res += index.get_documents(grams)\n",
    "        except IndexError as error:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "# get rank from \n",
    "def get_rank_from_counter_grams(res_grams, truth):\n",
    "    res = []\n",
    "    for i in res_grams.most_common():\n",
    "        res.append(i[0])\n",
    "    try:\n",
    "        rank = get_rank(res, truth)\n",
    "    except ValueError as error:\n",
    "        rank = sys.maxsize\n",
    "    return rank\n",
    "\n",
    "# get rank with relative pitch 4-grams (RP4G), 3-grams (RP3G) and 2-grams (RP2G)\n",
    "def get_rank_with_rpg(dis_query, truth):\n",
    "    index4G, index3G, index2G = get_inverted_index_midi(dis_midi, list_dir_midi)\n",
    "    query4G, query3G, query2G = get_ngrams_query(dis_query)\n",
    "\n",
    "    # 4-grams\n",
    "    res_4grams = get_counter_grams(index4G, query4G)\n",
    "\n",
    "    # 3-grams\n",
    "    res_3grams = get_counter_grams(index3G, query3G)\n",
    "\n",
    "    # 2-grams\n",
    "    res_2grams = get_counter_grams(index2G, query2G)\n",
    "\n",
    "    res_rank = []\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_4grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_3grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    rank = get_rank_from_counter_grams(res_2grams, truth)\n",
    "    res_rank.append(rank)\n",
    "\n",
    "    return res_rank\n",
    "\n",
    "# get rank with Mode Normalised Frequency using edit distance method\n",
    "def get_rank_with_mnf(df_query, truth):\n",
    "    # ref = dis_midi\n",
    "    # hyp = dis_query\n",
    "\n",
    "    hyp = convert_df_to_MNF(df_query)\n",
    "    midi = []\n",
    "    for i in df_midi:\n",
    "        midi.append(convert_df_to_MNF(i))\n",
    "    \n",
    "    list_ratio = []\n",
    "    for ref in midi:\n",
    "        sm = edit_distance.SequenceMatcher(a=ref, b=hyp)\n",
    "        list_ratio.append(sm.ratio())\n",
    "    \n",
    "    rank = get_all_rank(list_ratio)\n",
    "    rankTruth = get_rank(rank, truth)\n",
    "\n",
    "    # show all rank\n",
    "    # print(\"All rank from MNF:\", rank)\n",
    "\n",
    "    # show top ten result\n",
    "    # print(\"Top ten from MNF:\", get_top_ten(rank))\n",
    "\n",
    "#     try:\n",
    "#         rankTruth = get_rank(rank, truth)\n",
    "#     except ValueError as error:\n",
    "#         rankTruth = len(dis_midi)\n",
    "    # topTen = get_top_ten(rank)\n",
    "\n",
    "    return rankTruth\n",
    "\n",
    "# get best rank from both nGrams and edit distance method\n",
    "def get_rank_with_unified_algorithm(dis_query, df_query, truth):\n",
    "    res = get_rank_with_rpg(dis_query, truth)\n",
    "\n",
    "    # comment lines below if not using MNF for faster retrieval\n",
    "    try:\n",
    "        res.append(get_rank_with_mnf(df_query, truth))\n",
    "    except ValueError as error:\n",
    "        pass\n",
    "    except IndexError as error:\n",
    "        pass\n",
    "\n",
    "    bestRank = min(res)\n",
    "    return bestRank\n",
    "\n",
    "# convert one dataframe containing semitone to Mode Normalised Frequency (MNF)\n",
    "def convert_df_to_MNF(df):\n",
    "    from collections import Counter\n",
    "    res = []\n",
    "    data = Counter(df)\n",
    "\n",
    "    data = data.most_common()\n",
    "    mode = data[0][0]\n",
    "    adder = int(78-mode) # mode marked as char 'N' which is 78 in ascii\n",
    "\n",
    "    for i in df:\n",
    "        res.append(chr(int(i+adder)))\n",
    "    res = remove_consecutive(res)\n",
    "    return res\n",
    "\n",
    "# count MRR from a list of rank from some queries\n",
    "def count_MRR(list_rank):\n",
    "    mrr = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            mrr+=1/rank\n",
    "            counter+=1\n",
    "    return round(mrr/counter,2), counter\n",
    "\n",
    "# count top 3 hit ratios from list rank\n",
    "def count_top_3_ratio(list_rank):\n",
    "    count_top3 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 3:\n",
    "                count_top3+=1\n",
    "            counter+=1\n",
    "    return round(count_top3/counter,2), counter\n",
    "\n",
    "# count top 5 hit ratios from list rank\n",
    "def count_top_5_ratio(list_rank):\n",
    "    count_top5 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 5:\n",
    "                count_top5+=1\n",
    "            counter+=1\n",
    "    return round(count_top5/counter,2), counter\n",
    "\n",
    "# count top 10 hit ratios from list rank\n",
    "def count_top_10_ratio(list_rank):\n",
    "    count_top10 = 0\n",
    "    counter = 0\n",
    "    for rank in list_rank:\n",
    "        if not rank == sys.maxsize:\n",
    "            if rank <= 10:\n",
    "                count_top10+=1\n",
    "            counter+=1\n",
    "    return round(count_top10/counter,2), counter\n",
    "\n",
    "def print_result_to_file(process_name):\n",
    "    from datetime import datetime\n",
    "\n",
    "    dateTimeObj = str(datetime.now())+\".txt\"\n",
    "    dateTimeObj = dateTimeObj.replace(\":\",\"-\")\n",
    "    filename = os.path.join(folder_hasil, process_name + ' ' + dateTimeObj)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(cap.stdout)\n",
    "\n",
    "def process_query():\n",
    "    process_name = dir_query.replace(folder_data+\"\\\\\",\"\")+\" with \"+dir_midi.replace(folder_data+\"\\\\\",\"\")\n",
    "    print(\"Start process\", process_name)\n",
    "\n",
    "    for i in range(len(dis_query)):\n",
    "        print(\"Processing...\",i+1,\"/\",len(dis_query))\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        rankTruth = get_rank_with_unified_algorithm(dis_query[i], df_query[i], truth[i])\n",
    "        \n",
    "        list_time.append(round(time.time() - start_time, 3))\n",
    "\n",
    "        list_rank.append(rankTruth)\n",
    "\n",
    "        # show ground truth from a query\n",
    "        # print(\"query\",list_query_name[i],\"truth is\",truth[i])\n",
    "\n",
    "        print(\"query\",list_query_name[i],\"truth is on rank\",rankTruth)\n",
    "\n",
    "    print(\"Finish process\", process_name)\n",
    "    \n",
    "    try:\n",
    "        mrr, counter = count_MRR(list_rank)\n",
    "        print(\"MRR:\", mrr, \"from\", counter, \"queries\")\n",
    "\n",
    "        hit_ratio, counter = count_top_3_ratio(list_rank)\n",
    "        print(\"Top 3 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_5_ratio(list_rank)\n",
    "        print(\"Top 5 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "\n",
    "        hit_ratio, counter = count_top_10_ratio(list_rank)\n",
    "        print(\"Top 10 ratio:\", hit_ratio, \"from\", counter, \"queries\" )\n",
    "        \n",
    "        print(\"Avg time:\", round(sum(list_time)/len(list_time), 3))\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        print(\"No result to show\")\n",
    "        print(\"list rank\", list_rank)\n",
    "        print(\"list time\", list_time)\n",
    "\n",
    "    return process_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1ed2c2a0f8f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# test match with query data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mprocess_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-cf37d347a7c5>\u001b[0m in \u001b[0;36mprocess_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mrankTruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rank_with_unified_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_query\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_query\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mlist_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cf37d347a7c5>\u001b[0m in \u001b[0;36mget_rank_with_unified_algorithm\u001b[1;34m(dis_query, df_query, truth)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;31m# comment lines below if not using MNF for faster retrieval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_rank_with_mnf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cf37d347a7c5>\u001b[0m in \u001b[0;36mget_rank_with_mnf\u001b[1;34m(df_query, truth)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmidi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medit_distance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequenceMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mlist_ratio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\edit_distance\\code.py\u001b[0m in \u001b[0;36mratio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;34m\"\"\"Ratio of matches to the average sequence length.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m2.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquick_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\edit_distance\\code.py\u001b[0m in \u001b[0;36mmatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m         :py:meth:`get_opcodes`.\"\"\"\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_distance_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\edit_distance\\code.py\u001b[0m in \u001b[0;36m_compute_distance_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m         d, m = edit_distance(self.seq1, self.seq2,\n\u001b[0;32m    198\u001b[0m                              \u001b[0maction_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                              test=self.test)\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\edit_distance\\code.py\u001b[0m in \u001b[0;36medit_distance\u001b[1;34m(seq1, seq2, action_function, test)\u001b[0m\n\u001b[0;32m    259\u001b[0m                                      del_match, sub_match, cost)\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEQUAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mREPLACE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 \u001b[0mv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                 \u001b[0mm1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "# read midi and query data\n",
    "# insert it into dataframe\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import edit_distance\n",
    "import time\n",
    "import sys\n",
    "\n",
    "folder_data = \"Data query dan midi\"\n",
    "folder_hasil = \"Hasil eksperimen\"\n",
    "\n",
    "if not os.path.exists(folder_hasil):\n",
    "    os.mkdir(folder_hasil)\n",
    "\n",
    "# test query\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_manual label\")\n",
    "\n",
    "# all query\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH\")\n",
    "dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_manual label\")\n",
    "\n",
    "# all midi\n",
    "# dir_midi = os.path.join(folder_data, \"Database midi MIR-QBSH\")\n",
    "dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH\")\n",
    "\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "if \"manual\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_manual_query(dir_query)\n",
    "elif \"IOACAS\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_IOACAS_query(dir_query)\n",
    "else:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_query(dir_query)\n",
    "\n",
    "# read and insert note_index or semitone from midi to list of dataframe\n",
    "list_dir_midi, df_midi = read_note_from_midi(dir_midi)\n",
    "\n",
    "# calculate relative distance in all query\n",
    "dis_query = []\n",
    "for query in df_query:\n",
    "    dis_query.append(calc_rel_dis(query))\n",
    "\n",
    "# calculate relative distance in all midi\n",
    "dis_midi = []\n",
    "for midi in df_midi:\n",
    "    dis_midi.append(calc_rel_dis(midi))\n",
    "\n",
    "# ref = dis_midi\n",
    "# hyp = dis_query\n",
    "\n",
    "list_rank = []\n",
    "list_time = []\n",
    "\n",
    "# test match with query data\n",
    "process_name = process_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cb51f0ab1fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_result_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-cf37d347a7c5>\u001b[0m in \u001b[0;36mprint_result_to_file\u001b[1;34m(process_name)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_hasil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdateTimeObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "print_result_to_file(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# read midi and query data\n",
    "# insert it into dataframe\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import edit_distance\n",
    "import time\n",
    "import sys\n",
    "\n",
    "folder_data = \"Data query dan midi\"\n",
    "folder_hasil = \"Hasil eksperimen\"\n",
    "\n",
    "if not os.path.exists(folder_hasil):\n",
    "    os.mkdir(folder_hasil)\n",
    "\n",
    "# test query\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Test query MIR-QBSH_manual label\")\n",
    "\n",
    "# all query\n",
    "dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_IOACAS_QBH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_DNN-LSTM\")\n",
    "# dir_query = os.path.join(folder_data, \"Query_MIR_QBSH_manual label\")\n",
    "\n",
    "# all midi\n",
    "# dir_midi = os.path.join(folder_data, \"Database midi MIR-QBSH\")\n",
    "dir_midi = os.path.join(folder_data, \"Database midi IOACAS-QBH\")\n",
    "\n",
    "\n",
    "# read and insert semitone from query to list of dataframe\n",
    "if \"manual\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_manual_query(dir_query)\n",
    "elif \"IOACAS\" in dir_query:\n",
    "    list_query_name, df_query, truth = read_semitone_from_IOACAS_query(dir_query)\n",
    "else:\n",
    "    list_query_name, df_query, truth = read_semitone_from_MIR_query(dir_query)\n",
    "\n",
    "# read and insert note_index or semitone from midi to list of dataframe\n",
    "list_dir_midi, df_midi = read_note_from_midi(dir_midi)\n",
    "\n",
    "# calculate relative distance in all query\n",
    "dis_query = []\n",
    "for query in df_query:\n",
    "    dis_query.append(calc_rel_dis(query))\n",
    "\n",
    "# calculate relative distance in all midi\n",
    "dis_midi = []\n",
    "for midi in df_midi:\n",
    "    dis_midi.append(calc_rel_dis(midi))\n",
    "\n",
    "# ref = dis_midi\n",
    "# hyp = dis_query\n",
    "\n",
    "list_rank = []\n",
    "list_time = []\n",
    "\n",
    "# test match with query data\n",
    "process_name = process_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result_to_file(process_name)"
   ]
  }
 ]
}